% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gph.R
\name{gph}
\alias{gph}
\title{gph function}
\usage{
gph(
  ct,
  X,
  nburnin = 1000,
  nmc = 5000,
  thin = 1,
  method.mcmc = c("MH", "slice"),
  prior = c("laplace", "horseshoe"),
  Xtest = NULL,
  cttest = NULL
)
}
\arguments{
\item{ct}{survival response, a \eqn{n*2} matrix with first column as response and 
second column as right censored indicator,
1 is event time and 0 is right censored.}

\item{X}{Matrix of covariates, dimension \eqn{n*p}.}

\item{nburnin}{number of burnin samples}

\item{nmc}{number of markov chain samples}

\item{thin}{thinning parameter. Default is 1 (no thinning)}

\item{method.mcmc}{which mcmc routine to employ between two options -- "MH" and "slice". 
MH stands for Metropolis Hestings}

\item{prior}{which prior to specify on the regression parameters between two options --
"laplace" and "horseshoe". "laplace" is equivalent to Bayesian LASSO.}

\item{Xtest}{test design matrix.}

\item{cttest}{test survival response.}
}
\value{
\item{BetaHat}{Posterior mean of \eqn{\beta}}
\item{BetaMedian}{Posterior median of \eqn{\beta}}
\item{Sigma2Hat}{Posterior mean of \eqn{\sigma^2}}
\item{gammaHat}{Posterior mean of \eqn{\gamma}}
\item{BetaSamples}{Posterior samples of \eqn{\beta}}
\item{Sigma2Samples}{Posterior samples of \eqn{\sigma^2}}
\item{gamma.initial}{Initial values of \eqn{\gamma}}
\item{gamma.samples}{Posterior samples of \eqn{\gamma}}
\item{SurvivalHat}{Posterior estimates of survival probability}
\item{LogTimeHat}{Posterior estimates of log survival time}
\item{DIC}{DIC of the fitted model}
\item{WAIC}{WAIC of the fitted model}
\item{LeftCI}{left boundaries of 95\% Bayesian credible intervals of \eqn{\beta}}
\item{RightCI}{right boundaries of 95\% Bayesian credible intervals of \eqn{\beta}}
}
\description{
MCMC routine for the density regression model
}
\examples{

set.seed(10)
n <- 249    # sample size
p <- 1000   # number of covariates
x <- mvtnorm::rmvnorm(n, mean = rep(0, p))  # design matrix
k <- 5  # number of true variables
beta.t <- c(sample(c(1, -1), size = k, replace = TRUE), rep(0, p - k))
linear.part <- as.vector(x \%*\% beta.t)
sigma.square <- 1

#cc <- 0.1
#dd <- 3
cc <- -7
dd <- 4

full.model <- 1:p
true.model <- which(beta.t != 0)
complement.model <- setdiff(full.model, true.model)

# Set the parameters
nburnin <- 10
nmc     <- 50
thin    <- 1
N       <- 61
sig     <- 2.5
nu      <- 0.1
#cc       <- min(log(time)) - 0.1
#dd       <- max(log(time)) + 0.1
knots   <- seq(from = cc, to = dd, length.out = N)
CM      <- gph:::covariance_matrix(knots, sig, nu)  # covariance matrix of g

y <- rnorm(n, mean = linear.part, sd = sqrt(sigma.square))  # response
T <- exp(y)   # AFT model
C <- truncdist::rtrunc(n, spec = "gamma", shape = 1, scale = 7, a = 5)  # 25\% censor
time <- pmin(T, C)  # observed time is min of censored and true
status = time == T   # set to 1 if event is observed
1 - sum(status)/length(y)   # censoring rate
censor.rate <- 1 - sum(status)/length(y)    # censoring rate
censor.rate
summary(C)
summary(T)
ct <- as.matrix(cbind(time = time, status = status))  # censored time
X <- scale(x)

# Training set and Test set
ntest       <- 50
ntrain      <- n - ntest
cttrain     <- ct[1:ntrain, ]
cttest      <- ct[(ntrain + 1):n, ]
test.index1 <- which(cttest[, 2] == 1)  # which are NOT censored
cttest1     <- cttest[test.index1, ]
Xtrain      <- X[1:ntrain, ]
Xtest       <- X[(ntrain + 1):n, ]

gph.fit <- gph(ct = cttrain, X = Xtrain, nburnin = nburnin, nmc = nmc, thin = thin, 
method.mcmc = "MH", prior = "horseshoe", Xtest = Xtest, cttest = cttest)

beta.post.gp <- gph.fit$BetaHat
cluster      <- kmeans(abs(beta.post.gp), centers = 2)$cluster  # return cluster indices
cluster1     <- which(cluster == 1)
cluster2     <- which(cluster == 2)
min.cluster  <- ifelse(length(cluster1) < length(cluster2), 1, 2)
prot.gp      <- which(cluster == min.cluster)
discovery    <- which(cluster == min.cluster)
correct.gp   <- as.numeric(setequal(discovery, true.model))
correct.gp
}
\references{
{Maity, A. K., Pati, D., and Mallick, B. K., (2022). 
Bayesian Time-to-event Data Density Regression with Application to High Dimensional Data.}
}
